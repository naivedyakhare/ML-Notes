{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd185c1a",
   "metadata": {},
   "source": [
    "## Exploring\n",
    "- Anthropic's Prompt generation.\n",
    "- Codestral (yet to do proper analysis on whether it performs better or not.\n",
    "- Function calling in Openai same as Tool calling in Cohere (tried with cohere, yet to try with openai)\n",
    "- Ollama - Phi-3 mini, llama3 70b (8b is too slow on 1050Ti 4GB, 8GB RAM.\n",
    "\n",
    "(VRAM != Virtual RAM LOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2ef383",
   "metadata": {},
   "source": [
    "# LLM-Based applications\n",
    "\n",
    "## Different GenAI API\n",
    "Coral (Free), GPT-3.5-turbo (Available with free tier), GPT-4-turbo, Gemini 1.5 Pro, Anthropic, Mistral\n",
    "\n",
    "- Codestral developed by Mistral is paid. It's code creation and completion performs better than most of the LLMs (as of 6th June 2024)\n",
    "\n",
    "## PoC for multiple LLM based applications\n",
    "- LIDA\n",
    "    - Microsoft's LIDA is a tool for automated visualisation and goal generation.\n",
    "    - Uses FASTAPI as backend.\n",
    "    - Some LLMs are outdated and needs to be updated.\n",
    "    - Does not work well with data related to clinical trials\n",
    "    - Slow\n",
    "    - Seaborn, matplotlib, ggplot for plot generation\n",
    "    - My changes\n",
    "        - LLM selection and API_KEY input through CLI\n",
    "        \n",
    "- Chat with PDFs\n",
    "    - Suggested by Kevin for Clinical Trial Docs being provided by clients during Data processing and analysing for Report generation\n",
    "    - Convert PDFs into chunks, sends them to OpenAI which vectorises it and is returned and stored in ChromaDB (or whatver vector store you want to use)\n",
    "    - VectorDB is then sent again along with the query to get response based on the PDF.\n",
    "    - Extremely slow for big PDFs\n",
    "    \n",
    "- Code from metadata (Mostly for Clinical Trials based dataset to Standardise the data based on SDTM guidelines\n",
    "    - Reads the SDTM Specs and writes a code that, when run by user in their SAS Enterprise, can directly convert the Raw data into SDTM data\n",
    "\n",
    "- Code from metadata Complete (The github is currently Private due to Data being used is sensetive)\n",
    "    - Yet to show this to Kevin\n",
    "    - Converts the raw data related to clinical trials directly into SDTM data. \n",
    "    - Uses python\n",
    "    - You need to change the name of the dataset to be processed inside the app2.py, run it and it will directly output the processed file based on SDTM. \n",
    "    - Proper prompting is important\n",
    "    - Fine tuning is not done since the required resources is not available, including a huge amount of dataset. Less dataset can lead to underfitting.\n",
    "    \n",
    "- Used Llama3 locally (yet to try other LLMs)\n",
    "    - Model name - llama3 8b\n",
    "    - Too slow due to low specs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
